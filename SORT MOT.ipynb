{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a3e00d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import cv2\n",
    "import csv\n",
    "import json\n",
    "import torchvision.models as models\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import threading\n",
    "import math\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "from torchvision import transforms\n",
    "from object_tracking import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bcbd74c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ahmed/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-4-18 Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\n",
      "Fusing layers... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\ahmed\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "EfficientNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2dNormActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "    (1): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "            (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(32, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(8, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (2): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "            (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(96, 4, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(4, 96, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0125, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.025, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (3): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 144, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=144, bias=False)\n",
       "            (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(144, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(6, 144, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(144, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.037500000000000006, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.05, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (4): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(240, 10, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(10, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.0625, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.07500000000000001, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.08750000000000001, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 20, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(20, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1125, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.125, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 28, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(28, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1375, mode=row)\n",
       "      )\n",
       "      (1): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.15000000000000002, mode=row)\n",
       "      )\n",
       "      (2): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1625, mode=row)\n",
       "      )\n",
       "      (3): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.17500000000000002, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (7): Sequential(\n",
       "      (0): MBConv(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(192, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
       "            (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (2): SiLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(1152, 48, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(48, 1152, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): SiLU(inplace=True)\n",
       "            (scale_activation): Sigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(1152, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (stochastic_depth): StochasticDepth(p=0.1875, mode=row)\n",
       "      )\n",
       "    )\n",
       "    (8): Conv2dNormActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): SiLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=True)\n",
       "    (1): Linear(in_features=1280, out_features=7, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "model.eval();\n",
    "\n",
    "class Image_Classifier(nn.Module):\n",
    "    def init(self):\n",
    "        super().init()\n",
    "        self.model = nn.Sequential(\n",
    "             Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1)),\n",
    "             ReLU(),\n",
    "             Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1)),\n",
    "             ReLU(),\n",
    "             MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False),\n",
    "             Flatten(start_dim=1, end_dim=-1),\n",
    "             Dropout(p=0.25, inplace=False),\n",
    "             Linear(in_features=6272, out_features=132, bias=True),\n",
    "             ReLU(),\n",
    "             Dropout(p=0.5, inplace=False),\n",
    "             Linear(in_features=132, out_features=11, bias=True),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "color_classifier = torch.load(\"2layers_colour_model.pt\")\n",
    "color_classifier = color_classifier.cuda()\n",
    "color_classifier.eval()\n",
    "\n",
    "body_classifier = torch.load('model.pt')\n",
    "body_classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1710a306",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "no object detected\n",
      "Video processing completed\n",
      "17.02169966697693\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    video_path = 'light traffic.mp4'\n",
    "    output_path = 'track_test.mp4'\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "    ffmpeg_cmd = f\"ffmpeg -y -f rawvideo -pix_fmt bgr24 -s {frame_width}x{frame_height} -r {fps} -i - -c:v libx264 -preset fast -crf 30 -pix_fmt nv12 -an -vcodec libx264 {output_path}\"\n",
    "\n",
    "    output_file = subprocess.Popen(ffmpeg_cmd.split(' '), stdin=subprocess.PIPE)\n",
    "    \n",
    "    mot_tracker = Sort(max_age=30, min_hits=60) \n",
    "\n",
    "    object_dict = {}\n",
    "\n",
    "    frame_cut = 0\n",
    "    frame_count = 0\n",
    "    clf_state = False\n",
    "#     color_thread = threading.Thread(target=color_classifier)\n",
    "#     color_thread.start()\n",
    "\n",
    "#     body_thread = threading.Thread(target=body_classifier)\n",
    "#     body_thread.start()\n",
    "    \n",
    "    start = time.time()\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print('Video processing completed')\n",
    "            break\n",
    "\n",
    "        frame_model = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        results = model(frame_model[frame_cut:])\n",
    "\n",
    "        track_bbs_ids = mot_tracker.update(results.xyxy[0][:,:4].cpu())\n",
    "        \n",
    "        \n",
    "        for x1, y1, x2, y2, obj_id in track_bbs_ids:\n",
    "            cx1 = int((x1 + x2) / 2)\n",
    "            cy1 = int((y1 + y2) / 2)\n",
    "            width = abs(x2 - x1)\n",
    "            height = abs(y2 - y1)\n",
    "            diagonal = math.sqrt(width**2 + height**2)\n",
    "            if obj_id not in object_dict:\n",
    "                    object_dict[obj_id] = {\n",
    "                        'bboxes': [(x1, y1, x2, y2)],\n",
    "                        'frames': [frame_count],\n",
    "                        'last_seen_frame': 0,\n",
    "                        'color_classifier_preds': [],\n",
    "                        'body_classifier_preds': []\n",
    "                    }\n",
    "            \n",
    "            if diagonal > 300 :\n",
    "                try:\n",
    "                    car_image = frame_model[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                    transforms.Resize((32,32)),])\n",
    "                    car_image = transform(car_image)\n",
    "                    car_image = car_image.cuda()\n",
    "                except:\n",
    "                    print('no object detected')\n",
    "                    continue\n",
    "                with torch.no_grad():\n",
    "                    color_output = color_classifier(car_image.unsqueeze(0))\n",
    "                    color_prediction = torch.argmax(color_output).item()\n",
    "                    color_name = ['black','blue','brown','green','grey','orange','pink','purple','red','white','yellow']\n",
    "                    color_class_name = color_name[color_prediction]\n",
    "\n",
    "                try:\n",
    "                    body_car_image = frame_model[int(y1):int(y2), int(x1):int(x2)]\n",
    "                    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                                    transforms.Resize((256,256)),])\n",
    "                    body_car_image = transform(body_car_image)\n",
    "                    body_car_image = body_car_image.cuda()\n",
    "                except:\n",
    "                    print('no object detected')\n",
    "                    continue\n",
    "\n",
    "                with torch.no_grad():\n",
    "                    body_output = body_classifier(body_car_image.unsqueeze(0))\n",
    "                    body_prediction = torch.argmax(body_output).item()\n",
    "                    body_name = ['Heavy-Duty', 'Lorry', 'Luxury', 'Pickup', 'SUV', 'Sedan', 'Van']\n",
    "                    body_class_name = body_name[body_prediction]\n",
    "                    clf_state = True\n",
    "\n",
    "            \n",
    "                if obj_id not in object_dict:\n",
    "                    object_dict[obj_id] = {\n",
    "                        'bboxes': [(x1, y1, x2, y2)],\n",
    "                        'frames':[frame_count],\n",
    "                        'last_seen_frame': 0,\n",
    "                        'color_classifier_preds': [color_prediction],\n",
    "                        'body_classifier_preds': [body_prediction]\n",
    "                    }\n",
    "                else:\n",
    "                    object_dict[obj_id]['bboxes'].append(( x1, y1, x2, y2))\n",
    "                    object_dict[obj_id]['frames'].append((frame_count))\n",
    "                    object_dict[obj_id]['color_classifier_preds'].append(color_prediction)\n",
    "                    object_dict[obj_id]['body_classifier_preds'].append(body_prediction)\n",
    "\n",
    "                object_dict[obj_id]['last_seen_frame'] = frame_count\n",
    "\n",
    "                # Calculate the mode prediction of the classifier for the tracked object\n",
    "                color_mode_pred = statistics.mode(object_dict[obj_id]['color_classifier_preds'])\n",
    "                object_dict[obj_id]['color_mode_pred'] = str(color_name[color_mode_pred])\n",
    "\n",
    "                body_mode_pred = statistics.mode(object_dict[obj_id]['body_classifier_preds'])\n",
    "                object_dict[obj_id]['body_mode_pred'] = str(body_name[body_mode_pred])\n",
    "\n",
    "            cv2.putText(frame, str(obj_id), (cx1, cy1), 0, 0.5, (255, 255, 255), 2)\n",
    "            if clf_state == True:\n",
    "                cv2.putText(frame, color_name[color_mode_pred], (int(x1), int(y1)), cv2.FONT_HERSHEY_SIMPLEX, 1, (203, 192, 255), 2)\n",
    "                cv2.putText(frame,  body_name[body_mode_pred], (int(cx1), int(y2)), cv2.FONT_HERSHEY_SIMPLEX, 1, (203, 192, 255), 2)\n",
    "                clf_state = False\n",
    "\n",
    "        output_file.stdin.write(frame.tobytes())\n",
    "\n",
    "\n",
    "        frame_count += 1\n",
    "#     color_thread.join()\n",
    "#     body_thread.join()\n",
    "    cap.release()\n",
    "    output_file.stdin.close()\n",
    "    output_file.wait()\n",
    "    end = time.time()\n",
    "    \n",
    "    print(end - start)\n",
    "    \n",
    "    with open(\"object_tracks.json\", \"w\") as f:\n",
    "        json.dump(object_dict, f, indent=4)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c254a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.xyxy[0][:,:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8b36d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for x1,y1,x2,y2, obj_id in track_bbs_ids:\n",
    "    print(x1,y1,x2,y2, obj_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d97bde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as T\n",
    "from PIL import Image\n",
    "transform = T.ToPILImage()\n",
    "img = transform(car_image)\n",
    "img.show()\n",
    "output=classifier(car_image.unsqueeze(0))\n",
    "prediction = torch.argmax(output).item()\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "56634688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_objects_by_prediction(color_mode, body_mode, object_dict):\n",
    "    object_ids = []\n",
    "    for obj_id, obj_data in object_dict.items():\n",
    "        if obj_data['color_mode_pred'] == color_mode and obj_data['body_mode_pred'] == body_mode:\n",
    "            object_ids.append(obj_id)\n",
    "    return object_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3db507c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_frames_and_last_seen(object_id, object_dict):\n",
    "    obj_data = object_dict[object_id]\n",
    "    frames = obj_data['frames']\n",
    "    last_seen = obj_data['last_seen_frame']\n",
    "    return frames, last_seen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "865392a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'131.0': {'bboxes': [[1367.3381959036108, 16.32118589066346, 1403.1466673776392, 39.76498049117248]], 'frames': [0], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '130.0': {'bboxes': [[910.9993898426983, 4.266929583372277, 926.8303220713642, 18.809503598390418], [859.2452365962313, 491.6265268149396, 1044.1579959386224, 732.5995086592402], [853.7285966096248, 522.4345149546751, 1048.6957148986871, 779.6076002068709], [847.6843444609761, 556.517152449702, 1052.7016148128225, 831.2031668875265], [844.8932896485501, 594.1583298166172, 1059.4849300909602, 890.3076378794478], [842.3038286308769, 604.1532211281492, 1063.385270653494, 915.8309895279772], [838.6403771647651, 634.4012940514706, 1067.3267651274223, 965.2335016752222], [833.4128423363992, 678.1479851224151, 1074.0273940511797, 1032.155246777155], [829.5590097318333, 713.8605170573517, 1081.3369021066787, 1069.9403238275956], [824.0834768773373, 734.9445728840391, 1088.7259741533173, 1087.6282098527627], [808.2063203419466, 797.2375369722326, 1085.2659084601041, 1109.35095743157], [801.2557034514141, 824.8568196593823, 1084.9218831999385, 1111.949263414175], [798.1024189983018, 877.9465569967583, 1090.511561453511, 1120.8239166568874]], 'frames': [0, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264], 'last_seen_frame': 264, 'color_classifier_preds': [8, 8, 8, 8, 8, 8, 5, 3, 4, 6, 4, 6], 'body_classifier_preds': [4, 5, 5, 5, 4, 5, 5, 5, 5, 2, 2, 2], 'color_mode_pred': 'red', 'body_mode_pred': 'Sedan'}, '129.0': {'bboxes': [[1703.180908613327, 62.43408967107503, 1757.350829667923, 94.76758574396403]], 'frames': [0], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '128.0': {'bboxes': [[1018.062988593966, 32.95485308361814, 1041.006835624784, 54.26505658435061], [1391.5719953549935, 524.4513339171095, 1602.1896422104703, 746.330499206217], [1396.8946578643845, 533.6827786997189, 1616.6882697321516, 766.9139431754188], [1414.4305196007874, 562.9496867418893, 1646.728472278345, 811.6750581471699], [1438.3710304516137, 606.0464596479052, 1687.2545949282037, 876.9533935007042], [1467.9037350569333, 655.1808015204405, 1736.41150663477, 951.6097740616202], [1500.81261106998, 707.3562435483717, 1794.0225104310712, 1029.07178012865], [1539.7235366274695, 750.977886403859, 1860.5061937156752, 1070.9407053543716], [1548.9340814996435, 766.802318967691, 1889.7232436650752, 1085.5971650049119], [1562.9441699414358, 810.0512747183245, 1914.8051465405508, 1103.149534127979], [1588.0331951602557, 873.8183718114699, 1942.4745333212927, 1120.152215779595]], 'frames': [0, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138], 'last_seen_frame': 138, 'color_classifier_preds': [6, 6, 8, 8, 6, 6, 1, 1, 6, 6], 'body_classifier_preds': [5, 5, 5, 5, 5, 5, 5, 4, 5, 5], 'color_mode_pred': 'pink', 'body_mode_pred': 'Sedan'}, '127.0': {'bboxes': [[968.3909913672309, 34.217550202062725, 991.0220945702691, 59.940103606531025], [1030.372337913827, 559.8467365165955, 1224.8677599851364, 808.1636255310557], [1032.8761989089994, 599.7831217377848, 1238.407655276158, 870.448578991038], [1034.9199576279311, 643.2243899171899, 1254.1081408020095, 942.1816105198156], [1033.7969005149828, 654.1907168952995, 1261.6775505306384, 973.3989733573598], [1036.5824385164947, 691.9556659113491, 1276.626024019327, 1034.573809360911], [1041.345751958132, 726.6442076522263, 1294.3038026740965, 1070.8608980774145], [1043.1573404863495, 771.0046791896734, 1313.9555734547514, 1094.1652076551356], [1031.2639190068944, 828.1954110972406, 1314.1068807754236, 1112.4477781289008], [1025.2821919242383, 900.2469711177868, 1326.0064269546688, 1124.25957319091], [1024.7337455571374, 932.0749445868914, 1328.648542305697, 1122.3847866826309]], 'frames': [0, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142], 'last_seen_frame': 142, 'color_classifier_preds': [3, 3, 3, 3, 3, 3, 4, 4, 4, 4], 'body_classifier_preds': [5, 5, 5, 5, 5, 5, 5, 5, 2, 2], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '126.0': {'bboxes': [[992.9724125625719, 66.29486472428526, 1027.8165278671156, 93.08211891829286], [1084.2136283731309, 540.7529771279872, 1285.3561873522983, 775.7580890182064], [1089.1644543591835, 577.1294183961985, 1301.3111962236846, 831.8191799646344], [1092.9382154277575, 616.6492162727858, 1318.7066945124973, 895.886085821567], [1092.393392028237, 626.870451045655, 1326.9844864613501, 923.6756214781749], [1094.0914545518237, 662.6579270175105, 1342.6459559184098, 984.8612164370372], [1101.7988515106733, 702.0045925103673, 1364.3953335787435, 1043.6403844033841], [1109.1803435256284, 736.7045749759691, 1386.5998789542896, 1076.1469423418837], [1115.8095326613545, 782.1792054398443, 1424.5101019573751, 1097.114403750985], [1111.6260122360845, 836.4860367433255, 1426.0982739100791, 1114.2675801890953], [1109.9596381545039, 860.9554964133389, 1425.6897398309047, 1115.2843602518371], [1104.0663646442501, 916.5159395852136, 1433.9161970431899, 1121.4325793751175]], 'frames': [0, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107], 'last_seen_frame': 107, 'color_classifier_preds': [3, 3, 3, 4, 3, 3, 3, 4, 4, 4, 4], 'body_classifier_preds': [4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '125.0': {'bboxes': [[1772.0476075295883, 65.18554347095176, 1828.4506834860367, 95.14615208568887]], 'frames': [0], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '124.0': {'bboxes': [[1014.5595088600684, 110.30157538148069, 1060.2236942649315, 154.5990288665662], [1075.6515895290484, 566.8108349550649, 1263.8067928983166, 800.5814493963895], [1079.8790871085855, 604.8730106672995, 1277.2120613801064, 855.3331458975038], [1085.155932207799, 650.7930962311824, 1294.9208807661287, 924.0053610610072], [1090.7055787256393, 705.1808823711438, 1315.499411650101, 1009.4806048379028], [1090.7123245949856, 719.7349323533847, 1325.0030063882023, 1046.2001521502136], [1095.6658252886373, 748.532209969438, 1340.471298575932, 1076.6761889016925], [1098.4597585607733, 791.0824743782382, 1356.4953095560857, 1097.5825460445662], [1099.6522314779038, 849.8218337369982, 1368.9288981375123, 1114.8746781049051]], 'frames': [0, 60, 61, 62, 63, 64, 65, 66, 67], 'last_seen_frame': 67, 'color_classifier_preds': [0, 0, 0, 0, 0, 0, 1, 4], 'body_classifier_preds': [5, 5, 5, 5, 5, 5, 5, 5], 'color_mode_pred': 'black', 'body_mode_pred': 'Sedan'}, '123.0': {'bboxes': [[1084.4075323208144, 107.75067122503341, 1134.7692254916856, 149.58538834527909], [1370.6101482238084, 546.7668440715879, 1598.9763983250434, 770.3480044230994], [1389.7637928766871, 583.7239183055666, 1634.3410806400352, 827.3404285051159], [1412.575566675756, 624.7225426936515, 1676.0004031156363, 892.9801395638168], [1437.9468317168353, 672.652401213646, 1724.90508356297, 970.6161366781762], [1443.7491660403057, 685.3383755534115, 1746.0805229270677, 1003.829873412075], [1468.328790195296, 718.1948843787743, 1791.9070461822705, 1053.4836679338332], [1495.2776352911915, 755.6486078113272, 1835.9073076550067, 1082.5731880542853], [1509.826558139934, 805.906294256223, 1878.752628119303, 1101.1540043328087], [1539.2078002119374, 866.7369957531886, 1918.3192576427473, 1116.3500866700929]], 'frames': [0, 60, 61, 62, 63, 64, 65, 66, 67, 68], 'last_seen_frame': 68, 'color_classifier_preds': [3, 3, 3, 3, 9, 3, 4, 4, 9], 'body_classifier_preds': [5, 5, 4, 5, 5, 5, 5, 5, 5], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '132.0': {'bboxes': [[1105.3471064875075, 18.623581869022694, 1130.7305302312425, 41.03355314074293]], 'frames': [1], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '133.0': {'bboxes': [[1013.6108704882145, 121.84063789588532, 1151.2343443555355, 168.6510918404428]], 'frames': [7], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '134.0': {'bboxes': [[963.5300900788501, 0.42060764323188415, 980.9631960539624, 15.249767227068409], [1067.9160682332968, 607.0905583461221, 1255.0807472663473, 850.5647495906964], [1068.0819343510798, 619.1671002170943, 1261.6781895336676, 876.2583891000567], [1071.587948107832, 657.6679199264182, 1275.102545672403, 933.7554315196088], [1077.9321145206122, 712.0521016707243, 1295.6354844417183, 1016.7019729997163], [1085.2168616030178, 755.6461010656575, 1316.11161594163, 1063.6595472798194], [1089.5936715255468, 808.3643481090162, 1334.4646944185677, 1093.8301671282918], [1085.7765437674705, 875.8368014403259, 1342.0204139899895, 1115.3311814791377], [1084.524359671389, 905.4669682949022, 1344.4328122222396, 1117.5333833726095]], 'frames': [19, 238, 239, 240, 241, 242, 243, 244, 245], 'last_seen_frame': 245, 'color_classifier_preds': [7, 3, 7, 7, 3, 3, 3, 3], 'body_classifier_preds': [5, 4, 5, 5, 5, 5, 5, 5], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '135.0': {'bboxes': [[1198.5133668536894, 34.00413890846038, 1214.7293089275606, 62.660053291246655]], 'frames': [45], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '137.0': {'bboxes': [[1411.0158077792237, 15.59559641160802, 1475.3728640957763, 34.75662221632167]], 'frames': [55], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '136.0': {'bboxes': [[1443.2164914332589, 14.735762525985704, 1475.8699343479911, 32.70846659999086]], 'frames': [55], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '142.0': {'bboxes': [[944.448937620512, 17.04388515146066, 975.7513662378897, 46.19396020479216]], 'frames': [152], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '145.0': {'bboxes': [[873.3711944225779, 17.853753434207654, 901.25734384727, 41.93909013343602], [413.1899200701672, 474.9486069350347, 621.3139325161973, 692.9301807850194], [382.88318838293304, 501.714538648339, 602.6471671267984, 732.7826820591446], [350.44836752489675, 534.0542732984028, 582.7361745228491, 781.7471079952257], [309.9825016492789, 570.9250708549874, 557.9417367220427, 838.2922202720898], [264.2188520972138, 611.8830140022596, 532.0347252042475, 902.776817027951], [244.44362761187946, 622.9321543891975, 525.6605011739331, 929.803182459183], [200.07582560323908, 657.9219132339088, 500.9885267400124, 989.312981025555], [147.04085048703877, 697.9818802331131, 468.3492446047208, 1046.7838795940618], [95.25912158003578, 737.6778485753429, 435.0084643963845, 1080.4661911543958], [45.5056902003613, 782.3651289855416, 399.92881569331064, 1100.4401715235292], [5.015682958466755, 840.6938564696394, 370.02894106419456, 1117.3409327714048]], 'frames': [183, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322], 'last_seen_frame': 322, 'color_classifier_preds': [0, 4, 3, 0, 4, 4, 4, 4, 4, 4, 4], 'body_classifier_preds': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 2], 'color_mode_pred': 'grey', 'body_mode_pred': 'Sedan'}, '148.0': {'bboxes': [[1075.9208047928466, 83.24875414582499, 1122.433033030088, 124.56638071685825], [1384.2569030692096, 544.6953048609372, 1597.811676675028, 774.6556296877992], [1390.8985271118768, 557.0571862838509, 1615.2204695320147, 801.5063108424214], [1413.1919352750665, 594.7684292211468, 1652.076246716516, 858.3991650219523], [1442.8125014850502, 647.0692377235671, 1701.9789541497294, 936.6477975201713], [1480.143511914994, 705.9884088601146, 1765.653935800928, 1023.112690145895], [1521.069864254942, 758.0108924123912, 1829.4984490120107, 1070.8893129990981], [1559.5665851194549, 823.2292927111587, 1888.456432880279, 1101.6956556507566], [1571.0625151506313, 850.6333670416178, 1912.3270402260403, 1108.4627322455976], [1596.2799996124472, 916.4433156882134, 1948.3480896946107, 1122.2481387309012]], 'frames': [192, 244, 245, 246, 247, 248, 249, 250, 251, 252], 'last_seen_frame': 252, 'color_classifier_preds': [3, 4, 4, 4, 4, 4, 4, 4, 4], 'body_classifier_preds': [2, 5, 5, 5, 5, 2, 5, 5, 5], 'color_mode_pred': 'grey', 'body_mode_pred': 'Sedan'}, '155.0': {'bboxes': [[1367.357956571506, 89.41820138019065, 1439.2653487537357, 139.62752835113528]], 'frames': [217], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '159.0': {'bboxes': [[884.0674381166316, 121.68265870045886, 939.037038360806, 178.28440651597887], [542.8242462635732, 536.3975173957459, 751.8482386198358, 770.9760281133623], [530.5535895259062, 546.0257659068785, 748.0597706193661, 791.710043984042], [504.1654703964086, 579.008857557814, 732.4983524220903, 840.3152568846774], [470.8942894139313, 618.0022038742981, 713.2185000745001, 897.3477419936281], [430.28784704939426, 665.6630430399264, 690.4098092818292, 970.6863458492983], [385.0665794766071, 712.1917505996332, 663.7490239426286, 1037.3303910147565], [336.9410779559553, 754.0101010336712, 633.6150432665482, 1075.3049119108318], [315.9682228068134, 769.4346295224889, 625.8176962926568, 1088.1759558640601], [279.40263962505577, 810.5570592805417, 604.5447223110089, 1103.4443657726922], [247.6980180855343, 870.7331608508674, 585.109286353507, 1117.8927132354793]], 'frames': [233, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289], 'last_seen_frame': 289, 'color_classifier_preds': [3, 3, 3, 3, 3, 0, 0, 0, 0, 4], 'body_classifier_preds': [5, 5, 5, 5, 5, 5, 5, 5, 5, 5], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '158.0': {'bboxes': [[984.0152415984326, 69.5345563179596, 1030.8969292418592, 113.65352155465312], [1066.7370959322816, 517.4352507813896, 1262.2081168124778, 754.1756080721561], [1069.398097181979, 552.6391980985754, 1276.573140981625, 809.2114485011678], [1068.5769822476352, 562.069843821929, 1283.5335241635446, 832.701232027164], [1071.9636258899159, 592.7472364654909, 1296.7697381782482, 880.2039526679591], [1077.0688939616857, 633.0059969858216, 1314.4098005052638, 942.9350870145893], [1081.8322209631485, 681.7245025163606, 1335.5854611028142, 1018.9212604675563], [1090.5504147029494, 721.3759819238056, 1358.9052540364803, 1064.9204116887481]], 'frames': [233, 303, 304, 305, 306, 307, 308, 309], 'last_seen_frame': 309, 'color_classifier_preds': [3, 3, 9, 3, 3, 3, 3], 'body_classifier_preds': [5, 5, 4, 5, 5, 5, 5], 'color_mode_pred': 'green', 'body_mode_pred': 'Sedan'}, '163.0': {'bboxes': [[953.1134096167166, 8.329594420731567, 986.8685123264224, 41.4860091821914]], 'frames': [265], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '165.0': {'bboxes': [[1364.7231765908705, 86.85574186644503, 1439.6487091335948, 136.1811578401563]], 'frames': [294], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '162.0': {'bboxes': [[852.3587559733419, 47.6485304754296, 888.5707953747619, 83.77354329845713]], 'frames': [297], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '168.0': {'bboxes': [[863.8626807755569, 12.827172614591355, 902.857870001861, 47.66615950901762]], 'frames': [316], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}, '172.0': {'bboxes': [[1791.0547222461435, 175.44359519107914, 1924.1391523925397, 279.381310085834]], 'frames': [334], 'last_seen_frame': 0, 'color_classifier_preds': [], 'body_classifier_preds': []}}\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'color_mode_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23308\\1754017766.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mobject_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mobject_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_objects_by_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolor_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbody_mode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mobj_id\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject_ids\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mframes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlast_seen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_object_frames_and_last_seen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobject_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_23308\\1679967235.py\u001b[0m in \u001b[0;36mfind_objects_by_prediction\u001b[1;34m(color_mode, body_mode, object_dict)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mobject_ids\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mobj_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mobject_dict\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mobj_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'color_mode_pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mcolor_mode\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mobj_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'body_mode_pred'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mbody_mode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mobject_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_id\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mobject_ids\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'color_mode_pred'"
     ]
    }
   ],
   "source": [
    "color_mode = 'red'\n",
    "body_mode = 'Sedan'\n",
    "data = open('object_tracks.json')\n",
    "object_dict = json.load(data)\n",
    "print(object_dict)\n",
    "object_ids = find_objects_by_prediction(color_mode, body_mode, object_dict)\n",
    "for obj_id in object_ids:\n",
    "    frames, last_seen = get_object_frames_and_last_seen(obj_id, object_dict)\n",
    "    print(f'Object {obj_id} appeared in frames {frames} and was last seen in frame {last_seen}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5db99d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
