{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e22c265c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from torchvision.transforms import functional as F\n",
    "import cv2\n",
    "import csv\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image, ImageDraw\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import subprocess\n",
    "import torch.nn as nn\n",
    "from sort.tracker import Sort\n",
    "from scipy.spatial.distance import cdist\n",
    "from filterpy.kalman import KalmanFilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d39ff7d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\ahmed/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2023-4-18 Python-3.9.13 torch-2.0.0+cu118 CUDA:0 (NVIDIA GeForce GTX 1660 SUPER, 6144MiB)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mrequirements:\u001b[0m C:\\Users\\ahmed\\.cache\\torch\\hub\\requirements.txt not found, check failed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fusing layers... \n",
      "YOLOv5m summary: 290 layers, 21172173 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Image_Classifier(\n",
       "  (model): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (9): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (10): ReLU()\n",
       "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1))\n",
       "    (13): ReLU()\n",
       "    (14): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (15): Flatten(start_dim=1, end_dim=-1)\n",
       "    (16): Linear(in_features=9216, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv5 model\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5m', pretrained=True)\n",
    "model.eval()\n",
    "class Image_Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Conv2d(3, 32,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(32, 64,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(64, 128,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(128, 256,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Conv2d(256, 256,(3,3)),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(9216, 10),\n",
    "        )\n",
    "        # Define the class labels\n",
    "        self.classes = ['Bus', 'Heavy-Duty', 'Lorry', 'Luxury', 'Motorbike', 'Pickup', 'SUV', 'Sedan', 'Three Wheel', 'Van']\n",
    "            \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "# Load Bedo model for car classification\n",
    "classifier = Image_Classifier()\n",
    "classifier.load_state_dict(torch.load(\"Bedo_model.pt\"))\n",
    "classifier = classifier.cuda()\n",
    "classifier.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7959ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_Bedo(video_path, output_path):\n",
    "    # Check that the models are loaded correctly\n",
    "    if not model:\n",
    "        print(\"Error: could not load YOLOv5 model\")\n",
    "        return\n",
    "    if not classifier:\n",
    "        print(\"Error: could not load Bedo model\")\n",
    "        return\n",
    "\n",
    "    # Check that the input video file exists and is readable\n",
    "    if not os.path.isfile(video_path):\n",
    "        print(f\"Error: input video file {video_path} does not exist or is not readable\")\n",
    "        return\n",
    "\n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "    # Get the frames per second and frame size of the video\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS) \n",
    "    frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) \n",
    "    frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))  \n",
    "\n",
    "    # Define the ffmpeg command to write the output video  \n",
    "    ffmpeg_cmd = f\"ffmpeg -y -f rawvideo -pix_fmt bgr24 -s {frame_width}x{frame_height} -r {fps} -i - -c:v libx264 -crf 18 -preset veryfast {output_path}\"  \n",
    "\n",
    "    # Open the output file for writing  \n",
    "    output_file = subprocess.Popen(ffmpeg_cmd.split(' '), stdin=subprocess.PIPE)  \n",
    "\n",
    "\n",
    "    # Loop through the frames of the video\n",
    "    while cap.isOpened():\n",
    "        # Read the next frame from the video\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # If there are no more frames, break out of the loop\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Run the frame through the YOLOv5 model\n",
    "        yolov5_results = model(frame)\n",
    "\n",
    "        # Check that the results contain valid bounding boxes\n",
    "        if len(yolov5_results.xyxy[0]) == 0:\n",
    "            continue\n",
    "\n",
    "        # Loop through the bounding boxes and classify the cars\n",
    "        for label, box, conf in zip(yolov5_results.xyxy[0][:, -1], yolov5_results.xyxy[0][:, :4], yolov5_results.xyxy[0][:, 4]):\n",
    "            box = [round(i, 2) for i in box.tolist()]\n",
    "            class_label = model.names[int(label)]\n",
    "\n",
    "            # Check if the class label is \"car\", \"truck\", \"bus\", \"bicycle\", or \"motorcycle\"\n",
    "            if class_label in [\"car\", \"truck\", \"bus\", \"bicycle\", \"motorcycle\"]:\n",
    "                # Ensure that the bounding box is within the bounds of the frame\n",
    "                x1, y1, x2, y2 = box\n",
    "                x1, y1, x2, y2 = max(0, int(x1)), max(0, int(y1)), min(frame.shape[1], int(x2)), min(frame.shape[0], int(y2))\n",
    "                if x1 >= x2 or y1 >= y2:\n",
    "                    continue\n",
    "\n",
    "                # Crop the car image from the frame\n",
    "                car_image = frame[y1:y2, x1:x2]\n",
    "\n",
    "                # Resize the car image to 256x256 using OpenCV functions\n",
    "                car_image = cv2.resize(car_image, (256, 256), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "                # Convert the car image to a PyTorch tensor\n",
    "                car_image = torch.from_numpy(car_image).permute(2, 0, 1).float().cuda()\n",
    "                car_image /= 255.0\n",
    "                \n",
    "                # Classify the car image using the Bedo model\n",
    "                with torch.no_grad():\n",
    "                    output = classifier(car_image.unsqueeze(0))\n",
    "                    prediction = torch.argmax(output).item()\n",
    "                    class_name = classifier.classes[prediction]\n",
    "\n",
    "                # Draw the bounding box and class label on the frame\n",
    "                font_scale = 0.5\n",
    "                thickness = 1  # Set the thickness to a larger value for a bolder font\n",
    "                cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "                cv2.putText(frame, class_name, (x1, y1), cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 0, 0), thickness+1)\n",
    "\n",
    "        # Write the frame to the output video\n",
    "        output_file.stdin.write(frame.tobytes()) \n",
    "\n",
    "    # Release the video file and close the output video\n",
    "    cap.release() \n",
    "    output_file.stdin.close() \n",
    "    output_file.wait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e8794f",
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_Bedo('india.mp4','test2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1ceea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
